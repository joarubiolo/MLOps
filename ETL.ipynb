{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTACION DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rubio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGA DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2661632247.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_movies = pd.read_csv(r'C:\\Users\\rubio\\Documents\\SoyHenry\\Proyecto_individual_2\\Dataset\\movies_dataset.csv') # Dataset de peliculas\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datasets en formato csv y las convertimos en dataframes con pandas\n",
    "df_movies = pd.read_csv(r'C:\\Users\\rubio\\Documents\\SoyHenry\\Proyecto_individual_2\\Dataset\\movies_dataset.csv') # Dataset de peliculas\n",
    "df_credits = pd.read_csv(r'C:\\Users\\rubio\\Documents\\SoyHenry\\Proyecto_individual_2\\Dataset\\credits.csv') # Dataset del staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL (EXTRACCION, TRANSFORMACION Y CARGA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas irrelevantes que no seran incluidas en el ETL ni el EDA\n",
    "df_movies.drop(columns={'homepage', 'video', 'imdb_id', 'adult', 'original_title', 'poster_path'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\870035887.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_movies['revenue'].fillna(value=0, inplace=True)\n",
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\870035887.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_movies['budget'].fillna(value=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Hacemos un llenado de valores nulos o Nan con el valor numerico 0, para que en el futuro no nos moleste en el calculo de la columna 'return'\n",
    "df_movies['revenue'].fillna(value=0, inplace=True)\n",
    "df_movies['budget'].fillna(value=0, inplace=True)\n",
    "print(df_movies['revenue'].isna().sum())  # Verificamos los valores faltantes en 'revenue'\n",
    "print(df_movies['budget'].isna().sum())  # Verificamos los valores faltantes en 'budget'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explotamos (en sentido figurado) y normalizamos la columna 'genres' debido a que tiene informacion anidada \n",
    "explode = df_movies['genres'].explode()\n",
    "norm = pd.json_normalize(explode).reset_index(drop=True)\n",
    "\n",
    "# Concatenamos la normalización con el dataframe original\n",
    "df_movies = pd.concat([df_movies, norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion para extraer valores de un diccionario dentro de una cadena 'str' ya que varias columnas tienen dicho formato\n",
    "def explode_dict(value,key): # Asignamos las variables: 'value' seria el valor de la columna y 'key' la clave que queremos extrer\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    try:\n",
    "        dicc = ast.literal_eval(value)  # Convertimos el valor string en un diccionario\n",
    "        if isinstance(dicc, dict):\n",
    "            return dicc.get(key, np.nan)  # Extraemos únicamente el valor asociado a la clave 'key'\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos el nombre de la colección que está dentro de la columna 'belongs_to_collection' con la clave 'name'\n",
    "df_movies['collection'] = df_movies['belongs_to_collection'].apply(explode_dict, key='name')\n",
    "df_movies.drop(columns={'belongs_to_collection'}, inplace=True)  # Eliminamos la columna original una vez extraido el valor mencionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion muy parecida a la anterior ya que hay columnas con una pequeña diferencia en los datos anidados con listas de diccionarios\n",
    "def explode_list(value, key):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    try:\n",
    "        lis = ast.literal_eval(value)\n",
    "        if isinstance(lis, list): \n",
    "            names = [item.get(key) for item in lis if isinstance(item, dict)]\n",
    "            return ', '.join(names) if names else np.nan  # Esto devuelve una cadena con los valores separados por comas\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la funcion para extraer los 'name' o nombres que hacen referencia al dato mas importante y luego se elimina la columna\n",
    "df_movies['generos'] = df_movies['genres'].apply(explode_list, key='name')\n",
    "df_movies.drop(columns={'genres'}, inplace=True)\n",
    "\n",
    "df_movies['country'] = df_movies['production_countries'].apply(explode_list, key='name')\n",
    "df_movies.drop(columns={'production_countries'}, inplace=True)\n",
    "\n",
    "df_movies['company'] = df_movies['production_companies'].apply(explode_list, key='name')\n",
    "df_movies.drop(columns={'production_companies'}, inplace=True)\n",
    "\n",
    "df_movies['language'] = df_movies['spoken_languages'].apply(explode_list, key='name')\n",
    "df_movies.drop(columns={'spoken_languages'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30000000.0\n",
       "1        65000000.0\n",
       "2               0.0\n",
       "3        16000000.0\n",
       "4               0.0\n",
       "            ...    \n",
       "45461           0.0\n",
       "45462           0.0\n",
       "45463           0.0\n",
       "45464           0.0\n",
       "45465           0.0\n",
       "Name: budget, Length: 45466, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conviertimos la columna de presupuesto en tipo numerico para poder hacer calculos posteriormente, conviertiendo errores en campos nulos\n",
    "df_movies['budget'] = pd.to_numeric(df_movies['budget'], errors='coerce')\n",
    "df_movies['revenue'].fillna(0)  # Hacemos llenado de valores faltantes en ganancia o 'revenue'\n",
    "df_movies['budget'].fillna(0)  # Lo mismo con presupuesto o 'budget'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función para calcular el retorno que se calcula con los valores de 'budget' y 'revenue'\n",
    "def calc_return(budget, revenue):\n",
    "    try:\n",
    "        b = int(budget)\n",
    "        r = revenue\n",
    "        if b == 0 or r == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            roi = r / b\n",
    "            return roi\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función de calculo de retorno sobre las filas de las columnas mencionadas\n",
    "df_movies['return'] = df_movies.apply(lambda row: calc_return(row['budget'], row['revenue']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas donde la fecha de lanzamiento sea nula porque fue solicitado\n",
    "df_movies.dropna(subset=['release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una función para cambiar el formato de las fechas\n",
    "def format_date(column):\n",
    "    try:\n",
    "        date = datetime.strptime(column, '%Y-%m-%d')  # Convierte a objeto datetime\n",
    "        return date\n",
    "    except(ValueError, TypeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la funcion para el formateo de fecha en la columna correspondiente\n",
    "df_movies['release_date'] = df_movies['release_date'].apply(format_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion para extraer solo el año de las fechas de lanzamiento\n",
    "def only_year(date):\n",
    "    year = date.year\n",
    "    return year\n",
    "\n",
    "# Y aplicamos dicha funcion en la columna que corresponde\n",
    "df_movies['release_year'] = df_movies['release_date'].apply(only_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'popularity' a tipo numérico para evitar conflictos mas adelante\n",
    "df_movies['popularity'] = pd.to_numeric(df_movies['popularity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos los datasets de películas y créditos para unificar los datos y alinearlos\n",
    "df = pd.concat([df_movies, df_credits], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una función para extraer los actores de la columna 'cast' que estan anidados de manera similar a otras columnas anteriores\n",
    "def extract_actors(columna):\n",
    "    try:\n",
    "        cast = ast.literal_eval(columna)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "    \n",
    "    return [actor.get('name') for actor in cast]\n",
    "\n",
    "# Y aplicamos\n",
    "df['actors'] = df['cast'].apply(extract_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para extraer los directores de la columna 'crew' que es mas compleja \n",
    "# ya que solo queremos el nombre del director entre otros miembros del staff\n",
    "def extract_directors(crew_list):\n",
    "    if isinstance(crew_list, str):\n",
    "        crew_list = ast.literal_eval(crew_list)\n",
    "    \n",
    "    directores = [d['name'] for d in crew_list if d.get('job') == 'Director']\n",
    "    return directores[0] if directores else None\n",
    "    \n",
    "# Y aplicamos\n",
    "df['director'] = df['crew'].apply(extract_directors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #1 cantidad_filmaciones_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una nueva columna con el mes de lanzamiento \n",
    "df['release_month'] = df['release_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un nuevo dataset solamente con las columnas que necesitaremos para el endpoint 1\n",
    "df_endpoint1 = df[['title','release_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\1750770614.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_endpoint1['release_month'] = df_endpoint1['release_month'].replace({1:'enero',2:'febrero', 3:'marzo', 4:'abril', 5:'mayo', 6:'junio', 7:'julio', 8:'agosto', 9:'septiembre', 10:'octubre', 11:'noviembre', 12:'diciembre'})\n"
     ]
    }
   ],
   "source": [
    "# Remplazamos los valores del mes en numeros por el nombre del mes para luego resulte mas sencilla la funcion \n",
    "df_endpoint1['release_month'] = df_endpoint1['release_month'].replace({1:'enero',2:'febrero', 3:'marzo', 4:'abril', 5:'mayo', 6:'junio', 7:'julio', 8:'agosto', 9:'septiembre', 10:'octubre', 11:'noviembre', 12:'diciembre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la funcion que buscara todas las filmaciones que fueron lanzadas en el mes introducido \n",
    "def cantidad_filmaciones_mes(mes:str):\n",
    "    filmaciones = df_endpoint1['title'][df_endpoint1['release_month'] == mes]\n",
    "    cantidad = filmaciones.count()\n",
    "    return f'{cantidad} películas fueron estrenadas en el mes de {mes}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5912 películas fueron estrenadas en el mes de enero'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y finalmente probamos la funcion\n",
    "cantidad_filmaciones_mes('enero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #2 cantidad_filmaciones_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una nueva columna pero esta vez colocamos el dia en lugar del mes\n",
    "df['release_day'] = df['release_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplazamos los dias de la semana que estan en ingles por su equivalente en español\n",
    "df['release_day'] = df['release_day'].replace({\n",
    "    'Monday': 'lunes', 'Tuesday': 'martes', 'Wednesday': 'miércoles',\n",
    "    'Thursday': 'jueves', 'Friday': 'viernes', 'Saturday': 'sábado', 'Sunday': 'domingo'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un dataframe orientado al uso del endpoint 2\n",
    "df_endpoint2 = df[['title', 'release_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la funcion que consiste en devolver la cantidad de peliculas estrenadas en el dia ingresado\n",
    "def cantidad_filmaciones_dia(dia:str):\n",
    "    filmaciones = df_endpoint2['title'][df_endpoint2['release_day'] == dia]\n",
    "    cantidad = filmaciones.count()\n",
    "    return f'{cantidad} películas fueron estrenadas en el dia {dia}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3503 películas fueron estrenadas en el dia lunes'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos dicha funcion\n",
    "cantidad_filmaciones_dia('lunes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #3 score_titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el dataframe para usar en el endpoint 3\n",
    "df_endpoint3 = df[['title','popularity','release_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la funcion que busca la pelicula en el dataframe y recopila los datos solicitados\n",
    "def score_titulo(titulo_de_la_filmacion:str):\n",
    "    film = df_endpoint3[df_endpoint3['title'] == titulo_de_la_filmacion]\n",
    "    title = film['title'].values[0]\n",
    "    year = film['release_year'].values[0]\n",
    "    score = film['popularity'].values[0]\n",
    "    return f'La película {title} fue estrenada en el año {int(year)} con un score/popularidad de {score}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La película Jumanji fue estrenada en el año 1995 con un score/popularidad de 17.015539'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos la funcion\n",
    "score_titulo('Jumanji')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #4 votos_titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos el dataframe para este endpoint\n",
    "df_endpoint4 = df[['title','release_year','vote_average','vote_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una funcion parecida al endpoint 3 y recopila informacion sobre los votos y otras caracteristicas de la pelicula\n",
    "def votos_titulo(titulo_de_la_filmacion:str):\n",
    "    film = df_endpoint4[df_endpoint4['title'] == titulo_de_la_filmacion]\n",
    "    valoraciones = film['vote_count'].values[0]\n",
    "    promedio = film['vote_average'].values[0]\n",
    "    año = film['release_year'].values[0]\n",
    "    titulo = film['title'].values[0]\n",
    "    if valoraciones < 2000:\n",
    "        return 'no cumple con la cantidad de valoraciones minimas'\n",
    "    else:\n",
    "        return f'La película {titulo} fue estrenada en el año {int(año)}. La misma cuenta con un total de {valoraciones} valoraciones, con un promedio de {promedio}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La película Jumanji fue estrenada en el año 1995. La misma cuenta con un total de 2413.0 valoraciones, con un promedio de 6.9'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos fijamos si funciona correctamente\n",
    "votos_titulo('Jumanji')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #5 get_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el dataframe para su uso en el endpoint 5\n",
    "df_endpoint5 = df[['title', 'actors', 'return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la funcion donde se filtra las peliculas que contienen el nombre del actor en la lista de actores del df\n",
    "def get_actor(nombre:str):\n",
    "    peliculas = df_endpoint5[df_endpoint5['actors'].apply(lambda actors: nombre in actors)] # Aca el filtro de peliculas con el actor mencionado\n",
    "    pelis = peliculas['title'].tolist()\n",
    "    retorno = peliculas['return'].tolist()\n",
    "    cantidad = len(pelis)\n",
    "    ganancia = sum(retorno)\n",
    "    promedio = ganancia/cantidad\n",
    "    return print(f'El actor {nombre} ha participado en {cantidad} filmaciones, el mismo ha conseguido un retorno de {round(ganancia,3)} millones con un promedio de {round(promedio,3)} millones por filmación')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El actor Adam Sandler ha participado en 47 filmaciones, el mismo ha conseguido un retorno de 72.031 millones con un promedio de 1.533 millones por filmación\n"
     ]
    }
   ],
   "source": [
    "# Probamos la funcion creada\n",
    "get_actor('Adam Sandler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT #6 get_director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimo dataframe para su uso en el endpoint 6\n",
    "df_endpoint6 = df[['title', 'return','director','release_date','budget','revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion es mas sencilla que get_actor debido a que en la columna directores solo hay un solo nombre\n",
    "def get_director(nombre:str):\n",
    "    peliculas_director = df_endpoint6[df_endpoint6['director'] == nombre]\n",
    "    if peliculas_director.empty:\n",
    "        return f\"No se encontraron películas para el director: {nombre}\"\n",
    "    retorno_total = peliculas_director['return'].sum()\n",
    "    informacion_peliculas = peliculas_director[['title', 'release_date', 'return', 'budget', 'revenue']]\n",
    "    return {\n",
    "        'nombre_director': nombre,\n",
    "        'retorno_total': retorno_total,\n",
    "        'informacion_peliculas': informacion_peliculas\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nombre_director': 'Christopher Nolan',\n",
       " 'retorno_total': 35.13215293098237,\n",
       " 'informacion_peliculas':                                         title release_date    return  \\\n",
       " 2466                                Following   1998-09-12  8.080333   \n",
       " 4099                                  Memento   2000-10-11  4.413677   \n",
       " 5254                                 Insomnia   2002-05-24  2.472062   \n",
       " 10122                           Batman Begins   2005-06-10  2.494791   \n",
       " 11354                            The Prestige   2006-10-19  2.741908   \n",
       " 12481                         The Dark Knight   2008-07-16  5.430046   \n",
       " 15480                               Inception   2010-07-14  5.159580   \n",
       " 18252                   The Dark Knight Rises   2012-07-16  4.339756   \n",
       " 22878  The Inevitable Defeat of Mister & Pete   2013-10-11  0.000000   \n",
       " 25896                              Stuntwoman   1977-10-05  0.000000   \n",
       " 25974            To Grandmother's House We Go   1992-12-06  0.000000   \n",
       " 44688                        Hurdy-Gurdy Hare   1950-01-20  0.000000   \n",
       " \n",
       "             budget       revenue  \n",
       " 2466        6000.0  4.848200e+04  \n",
       " 4099     9000000.0  3.972310e+07  \n",
       " 5254    46000000.0  1.137148e+08  \n",
       " 10122  150000000.0  3.742187e+08  \n",
       " 11354   40000000.0  1.096763e+08  \n",
       " 12481  185000000.0  1.004558e+09  \n",
       " 15480  160000000.0  8.255328e+08  \n",
       " 18252  250000000.0  1.084939e+09  \n",
       " 22878          0.0  0.000000e+00  \n",
       " 25896          0.0  0.000000e+00  \n",
       " 25974          0.0  0.000000e+00  \n",
       " 44688          0.0  0.000000e+00  }"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente probamos la funcion\n",
    "get_director('Christopher Nolan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SISTEMA DE RECOMENDACION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2072408389.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reco['title'] = df_reco['title'].fillna('')\n",
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2072408389.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reco['overview'] = df_reco['overview'].fillna('')\n",
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2072408389.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reco['generos'] = df_reco['generos'].fillna('')\n",
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2072408389.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reco['keywords'] = df_reco['overview'].apply(extract_keywords)\n",
      "C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_15652\\2072408389.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reco['combined_text'] = df_reco['generos'] + ' ' + df_reco['keywords']\n"
     ]
    }
   ],
   "source": [
    "# Armamos el dataframe con las columnas necesarias para hacer un sistema de recomendacion con NearestNeighbors\n",
    "df_reco = df[['title','overview','generos']]\n",
    "\n",
    "# Reemplazamos valores nulos en 'title', 'overview' y 'generos' con una cadena vacía para que no haya conflictos a la hora de procesar y extraer info\n",
    "df_reco['title'] = df_reco['title'].fillna('')\n",
    "df_reco['overview'] = df_reco['overview'].fillna('')\n",
    "df_reco['generos'] = df_reco['generos'].fillna('')\n",
    "\n",
    "# Inicializamos el extractor RAKE para insertarla en la siguiente funcion\n",
    "rake = Rake()\n",
    "\n",
    "# Creamos la funcion para extraer palabras clave que vamos a aplicar a una de las columnas\n",
    "def extract_keywords(text):\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    return ' '.join(rake.get_ranked_phrases())\n",
    "\n",
    "# Aplicamos la funcion de extracción de palabras clave a la columna 'overview'\n",
    "df_reco['keywords'] = df_reco['overview'].apply(extract_keywords)\n",
    "\n",
    "# Creamos una nueva columna combinando 'title', 'generos' y 'keywords' para tener toda la info necesaria para una buen sistema de recomendacion\n",
    "df_reco['combined_text'] = df_reco['generos'] + ' ' + df_reco['keywords']\n",
    "\n",
    "# Aplicamos una vectorizacion con TfidfVectorizer sobre el texto combinado anteriormente\n",
    "vect = TfidfVectorizer(stop_words='english', max_features=5000)  # Podemos ajustar 'max_features' para limitar la cantidad de palabras\n",
    "vect_matrix = vect.fit_transform(df_reco['combined_text'])\n",
    "\n",
    "# Usamos NearestNeighbors con los parametros elegidos y entrenamos el modelo\n",
    "nn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=6)\n",
    "nn_model.fit(vect_matrix)\n",
    "\n",
    "# Hacemos la función de recomendación\n",
    "def recomendacion(titulo):\n",
    "    if titulo not in df_reco['title'].values:\n",
    "        return f\"No se encontró la película: {titulo}\"\n",
    "\n",
    "    idx = df_reco[df_reco['title'] == titulo].index[0] # Aca se obtiene el indice de la pelicula ingresada\n",
    "\n",
    "    distances, indices = nn_model.kneighbors(vect_matrix[idx], n_neighbors=6) # El modelo busca y devuelve los indices de las peliculas similares\n",
    "\n",
    "    similar_titles = df_reco['title'].iloc[indices[0][1:]]  # Excluimos nuestra pelicula y devolvemos hasta 5 resultados\n",
    "    \n",
    "    return similar_titles.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story 3',\n",
       " 'The 40 Year Old Virgin',\n",
       " 'The Champ',\n",
       " 'Andy Kaufman Plays Carnegie Hall',\n",
       " \"Andy Hardy's Blonde Trouble\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el sitema de recomendacion y evaluamos el resultado\n",
    "recomendacion('Toy Story')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos los archivos para el EDA y el posterior deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_eda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los df de cada endpoint y del sistema de recomendacion en formato parquet\n",
    "df_endpoint1.to_parquet('end1.parquet')\n",
    "df_endpoint2.to_parquet('end2.parquet')\n",
    "df_endpoint3.to_parquet('end3.parquet')\n",
    "df_endpoint4.to_parquet('end4.parquet')\n",
    "df_endpoint5.to_parquet('end5.parquet')\n",
    "df_endpoint6.to_parquet('end6.parquet')\n",
    "df_reco.to_parquet('reco.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
